Когда завершите задачу, в этом README опишите свой ход мыслей: как вы пришли к решению, какие были варианты и почему выбрали именно этот. 

# Что нужно сделать

Реализовать интерфейс с методом для проверки правил флуд-контроля. Если за последние N секунд вызовов метода Check будет больше K, значит, проверка на флуд-контроль не пройдена.

- Интерфейс FloodControl располагается в файле main.go.

- Флуд-контроль может быть запущен на нескольких экземплярах приложения одновременно, поэтому нужно предусмотреть общее хранилище данных. Допустимо использовать любое на ваше усмотрение. 

# Необязательно, но было бы круто

Хорошо, если добавите поддержку конфигурации итоговой реализации. Параметры — на ваше усмотрение.

# Решение

Во-первых сначала нужно объяснить алгоритм решения. Мы имеем хэш-таблицу счетчик, в которой ключом является 
id, а значением -- количество вызовов за последние N секунд. Также мы имеем очередь, в которой id хранятся
вместе с временем вызова функции, упорядоченные по времени. То есть при вызове метод Check мы делаем инкремент
соответсвующему пользователю в хэштаблице, после чего добавляем в конец очереди id и время вызова и проходимся 
по началу очереди, удаляя вхождения которые произошли больше N секунд назад и декрементируем соответсвующие
значения в хэш-таблице. Таким образом у этой операции получается средняя амортизационная стоимость равная единице, 
Очевидным решением в данном случае является хранить в базе данных логи, когда какой юзер вызвал метод 
Check, и просто при запросе любого экземпляра запрашивать из базы данных все запросы в 
промежутке от now() - N до now(). Главная проблема этой реализации это необходимость пересчитывать каждому
приложению каждый раз пересчитывать одни и те же данные. Однако есть способ сделать это в самой базе данных,
но с некоторыми оговорками.

Основной вопрос заключается в том каким образом мы выбираем время запроса. То есть если считать временем запроса
тот момент когда был вызван метод Check, нам каждый раз обращаясь в базу данных нужно запрашивать все записи, 
находящиеся в интересуещем нам временном промежутке [now() - N, now()]. Мы должны будем пройтись по всем этим записям и 
добавить их к нашей очереди, если вдруг с момента прошлого запроса в старом временном промежутке появились новые id, 
актуальные для нас сейчас. Поэтому логичней это время определять в самой базе данных автоматически через вызов now().
Тогда нам нужно будет проверять только id появившиеся после последнего вызова.

Мне показалось интересной идеей реализовать систему флуд контроля целиком в postgres. 
Я сделал отношение из id юзера и времени вызова запроса в бд(timesAndUsers) с которой строится индекс в виде бинарного дерева по времение вызова(timesAndUsersIndex), 
а также вторую таблицу(Count), которая ведет роль счетчика количества вызовов Check() для юзера за последние 
N секунд. При использовании метода Check() в бд вызывается функция TimeInsert(myUserId BIGINT), которая добавляет новый ряд
в отношение timesAndUsers, в ответ на что будет вызван триггер, который либо инкрементирует нужный ряд в таблице Count, 
либо добавит новый, если кортежа с нужным userId нет. После этого будет вызван DELETE на все ряды, которые вышли за пределы нашего временного промежутка.
При DELETE вызывается триггер который декрементирует соответсвующие кортежи в Count. По итогу возвращается число из таблички Count.
Число N в данном случае общее для всех приложений, потому что оно нужно для оптимальной работы
функции, так как если для каждого приложения ставить разное N необходимо будет при каждом запросе пересчитывать
количество вхождений нужного id(что немножко убивает идею решения которое работает за амортизационную единицу),
однако число K можно менять для каждого нового экземпляра класса, и число N также можно поменять через 
CREATE OR REPLACE FUNCTION, либо же через метод класса FloodControlImpl ChangeSecondsTo(seconds int). 
Главным преимуществом этого решения является отсутствие необходимости пересчитывать для каждого приложения запросы, 
из-за чего по времени работы оно является самым оптимальным. По итогу этот вариант мне понравился больше всего из-за возможности 
показать знания postgres и скорости работы. Конечно в следствии этого появляются некоторые ограничения/недостатки, 
но преимущества(высокая скорость + не надо использовать дополнительную память, храня данные в каждом приложении)
как мне кажется сильно перевешивают их. Опять таки можно обойти проблему с дополнительной памятью считая
все каждый раз в самой бд(расчеты для разных временных промежутков), но это будет очевидно занимать больше времени.

upFirst.sql -- файл описывающий базу данных и функции базы.